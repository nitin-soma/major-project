{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Classifier Training for GradCAM Explanation\n",
    "\n",
    "This notebook trains VGG16, ResNet50, and InceptionV3 classifiers on the Food11 dataset.\n",
    "The trained models will be used for GradCAM-based explainability analysis.\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "### For Kaggle:\n",
    "1. Add the Food11 dataset to your notebook\n",
    "2. Update `DATASET_PATH` below to point to the dataset location\n",
    "3. Enable GPU accelerator (Settings → Accelerator → GPU)\n",
    "\n",
    "### For Colab:\n",
    "1. Upload your dataset or mount Google Drive\n",
    "2. Enable GPU (Runtime → Change runtime type → GPU)\n",
    "3. Update `DATASET_PATH` accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (if needed)\n",
    "# !pip install tensorflow matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= CONFIGURATION =============\n",
    "# Update these paths according to your environment\n",
    "\n",
    "# For Kaggle (example):\n",
    "# DATASET_PATH = '/kaggle/input/food11-image-dataset/food11'\n",
    "\n",
    "# For Colab with Google Drive:\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# DATASET_PATH = '/content/drive/MyDrive/Datasets/Food'\n",
    "\n",
    "# For local or custom path:\n",
    "DATASET_PATH = 'Datasets/Food/training'  # Update this!\n",
    "\n",
    "# Output directory for models\n",
    "OUTPUT_DIR = 'models/Food'\n",
    "LOGS_DIR = 'logs'\n",
    "\n",
    "# Training parameters\n",
    "IMG_SIZE = (256, 256)\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.1\n",
    "INITIAL_EPOCHS = 10\n",
    "FINE_TUNE_EPOCHS = 10\n",
    "\n",
    "# Model selection (set to True to train that model)\n",
    "TRAIN_VGG16 = True\n",
    "TRAIN_RESNET50 = True\n",
    "TRAIN_INCEPTIONV3 = True\n",
    "\n",
    "# =========================================\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Dataset path: {DATASET_PATH}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Image size: {IMG_SIZE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_generators(dataset_path, img_size, batch_size, validation_split):\n",
    "    \"\"\"\n",
    "    Create training and validation data generators with augmentation\n",
    "    \"\"\"\n",
    "    # Training data generator with augmentation\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=validation_split,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Validation data generator (only rescaling)\n",
    "    val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=validation_split\n",
    "    )\n",
    "    \n",
    "    # Training generator\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        dataset_path,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Validation generator\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        dataset_path,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator\n",
    "\n",
    "# Create generators\n",
    "train_gen, val_gen = create_data_generators(\n",
    "    DATASET_PATH, IMG_SIZE, BATCH_SIZE, VALIDATION_SPLIT\n",
    ")\n",
    "\n",
    "num_classes = len(train_gen.class_indices)\n",
    "print(f\"\\nNumber of classes: {num_classes}\")\n",
    "print(f\"Class labels: {train_gen.class_indices}\")\n",
    "print(f\"Training samples: {train_gen.samples}\")\n",
    "print(f\"Validation samples: {val_gen.samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "def visualize_samples(generator, num_samples=9):\n",
    "    \"\"\"\n",
    "    Visualize sample images from the generator\n",
    "    \"\"\"\n",
    "    images, labels = next(generator)\n",
    "    class_names = {v: k for k, v in generator.class_indices.items()}\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        axes[i].imshow(images[i])\n",
    "        label_idx = np.argmax(labels[i])\n",
    "        axes[i].set_title(f\"Class: {class_names[label_idx]}\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Sample training images:\")\n",
    "visualize_samples(train_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Building Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(backbone_name, input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Build a classification model with specified backbone\n",
    "    \n",
    "    Args:\n",
    "        backbone_name: 'VGG16', 'ResNet50', or 'InceptionV3'\n",
    "        input_shape: Input image shape (height, width, channels)\n",
    "        num_classes: Number of output classes\n",
    "    \n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    # Select backbone\n",
    "    if backbone_name == 'VGG16':\n",
    "        base_model = tf.keras.applications.VGG16(\n",
    "            input_shape=input_shape,\n",
    "            include_top=False,\n",
    "            weights='imagenet'\n",
    "        )\n",
    "    elif backbone_name == 'ResNet50':\n",
    "        base_model = tf.keras.applications.ResNet50(\n",
    "            input_shape=input_shape,\n",
    "            include_top=False,\n",
    "            weights='imagenet'\n",
    "        )\n",
    "    elif backbone_name == 'InceptionV3':\n",
    "        base_model = tf.keras.applications.InceptionV3(\n",
    "            input_shape=input_shape,\n",
    "            include_top=False,\n",
    "            weights='imagenet'\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown backbone: {backbone_name}\")\n",
    "    \n",
    "    # Freeze base model\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build classification head\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu', kernel_initializer='he_normal')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu', kernel_initializer='he_normal')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Test model building\n",
    "print(\"Testing model building...\")\n",
    "test_model, test_base = build_model('VGG16', (*IMG_SIZE, 3), num_classes)\n",
    "print(f\"✓ Model built successfully\")\n",
    "print(f\"Total parameters: {test_model.count_params():,}\")\n",
    "print(f\"Trainable parameters: {sum([tf.size(w).numpy() for w in test_model.trainable_weights]):,}\")\n",
    "del test_model, test_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, train_gen, val_gen, initial_epochs=10, fine_tune_epochs=10):\n",
    "    \"\"\"\n",
    "    Train a model with two-phase training: frozen base + fine-tuning\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"Training: {model_name}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Build model\n",
    "    model, base_model = build_model(model_name, (*IMG_SIZE, 3), num_classes)\n",
    "    \n",
    "    # Create output directory\n",
    "    model_dir = os.path.join(OUTPUT_DIR, model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # ========== PHASE 1: Train with frozen base ==========\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"PHASE 1: Training with frozen base model\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Compile model\n",
    "    if model_name == 'VGG16':\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_acc')]\n",
    "    )\n",
    "    \n",
    "    # Callbacks for phase 1\n",
    "    callbacks_phase1 = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(model_dir, 'phase1_best.h5'),\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        ),n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=2,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=os.path.join(LOGS_DIR, model_name, 'phase1'),\n",
    "            histogram_freq=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train phase 1\n",
    "    history1 = model.fit(\n",
    "        train_gen,\n",
    "        epochs=initial_epochs,\n",
    "        validation_data=val_gen,\n",
    "        callbacks=callbacks_phase1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # ========== PHASE 2: Fine-tuning ==========\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"PHASE 2: Fine-tuning with unfrozen layers\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Unfreeze base model (last few layers)\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    # Freeze all but the last 4 layers\n",
    "    for layer in base_model.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    print(f\"Unfrozen layers: {sum([1 for layer in base_model.layers if layer.trainable])}\")\n",
    "    \n",
    "    # Recompile with lower learning rate\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_acc')]\n",
    "    )\n",
    "    \n",
    "    # Callbacks for phase 2\n",
    "    callbacks_phase2 = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(model_dir, 'Epoch={epoch:02d}-Loss={val_loss:.2f}-Acc={val_accuracy:.2f}.h5'),\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=2,\n",
    "            min_lr=1e-8,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=os.path.join(LOGS_DIR, model_name, 'phase2'),\n",
    "            histogram_freq=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train phase 2\n",
    "    history2 = model.fit(\n",
    "        train_gen,\n",
    "        epochs=fine_tune_epochs,\n",
    "        validation_data=val_gen,\n",
    "        callbacks=callbacks_phase2,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Save final model\n",
    "    final_path = os.path.join(model_dir, f'{model_name}_final.h5')\n",
    "    model.save(final_path)\n",
    "    print(f\"\\n✓ Final model saved to: {final_path}\")\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\nEvaluating model on validation set...\")\n",
    "    results = model.evaluate(val_gen, verbose=0)\n",
    "    print(f\"\\nFinal Validation Metrics:\")\n",
    "    print(f\"  Loss: {results[0]:.4f}\")\n",
    "    print(f\"  Accuracy: {results[1]:.4f}\")\n",
    "    print(f\"  Top-3 Accuracy: {results[2]:.4f}\")\n",
    "    \n",
    "    return model, history1, history2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history1, history2, model_name):\n",
    "    \"\"\"\n",
    "    Plot training history for both phases\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Combine histories\n",
    "    epochs1 = len(history1.history['accuracy'])\n",
    "    epochs2 = len(history2.history['accuracy'])\n",
    "    total_epochs = epochs1 + epochs2\n",
    "    \n",
    "    # Accuracy - Phase 1\n",
    "    axes[0, 0].plot(history1.history['accuracy'], label='Train Accuracy', marker='o')\n",
    "    axes[0, 0].plot(history1.history['val_accuracy'], label='Val Accuracy', marker='s')\n",
    "    axes[0, 0].axvline(x=epochs1-1, color='r', linestyle='--', label='Phase 1 End')\n",
    "    axes[0, 0].set_title(f'{model_name} - Phase 1: Accuracy')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss - Phase 1\n",
    "    axes[0, 1].plot(history1.history['loss'], label='Train Loss', marker='o')\n",
    "    axes[0, 1].plot(history1.history['val_loss'], label='Val Loss', marker='s')\n",
    "    axes[0, 1].axvline(x=epochs1-1, color='r', linestyle='--', label='Phase 1 End')\n",
    "    axes[0, 1].set_title(f'{model_name} - Phase 1: Loss')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy - Phase 2\n",
    "    axes[1, 0].plot(range(epochs1, epochs1+epochs2), history2.history['accuracy'], \n",
    "                    label='Train Accuracy', marker='o')\n",
    "    axes[1, 0].plot(range(epochs1, epochs1+epochs2), history2.history['val_accuracy'], \n",
    "                    label='Val Accuracy', marker='s')\n",
    "    axes[1, 0].set_title(f'{model_name} - Phase 2: Accuracy')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Accuracy')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss - Phase 2\n",
    "    axes[1, 1].plot(range(epochs1, epochs1+epochs2), history2.history['loss'], \n",
    "                    label='Train Loss', marker='o')\n",
    "    axes[1, 1].plot(range(epochs1, epochs1+epochs2), history2.history['val_loss'], \n",
    "                    label='Val Loss', marker='s')\n",
    "    axes[1, 1].set_title(f'{model_name} - Phase 2: Loss')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Loss')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, model_name, f'{model_name}_training_history.png'), \n",
    "                dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store trained models and histories\n",
    "trained_models = {}\n",
    "\n",
    "# Train VGG16\n",
    "if TRAIN_VGG16:\n",
    "    model_vgg, hist1_vgg, hist2_vgg = train_model(\n",
    "        'VGG16', train_gen, val_gen, \n",
    "        INITIAL_EPOCHS, FINE_TUNE_EPOCHS\n",
    "    )\n",
    "    trained_models['VGG16'] = (model_vgg, hist1_vgg, hist2_vgg)\n",
    "    plot_training_history(hist1_vgg, hist2_vgg, 'VGG16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ResNet50\n",
    "if TRAIN_RESNET50:\n",
    "    model_resnet, hist1_resnet, hist2_resnet = train_model(\n",
    "        'ResNet50', train_gen, val_gen, \n",
    "        INITIAL_EPOCHS, FINE_TUNE_EPOCHS\n",
    "    )\n",
    "    trained_models['ResNet50'] = (model_resnet, hist1_resnet, hist2_resnet)\n",
    "    plot_training_history(hist1_resnet, hist2_resnet, 'ResNet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train InceptionV3\n",
    "if TRAIN_INCEPTIONV3:\n",
    "    model_inception, hist1_inception, hist2_inception = train_model(\n",
    "        'InceptionV3', train_gen, val_gen, \n",
    "        INITIAL_EPOCHS, FINE_TUNE_EPOCHS\n",
    "    )\n",
    "    trained_models['InceptionV3'] = (model_inception, hist1_inception, hist2_inception)\n",
    "    plot_training_history(hist1_inception, hist2_inception, 'InceptionV3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all trained models\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results_comparison = []\n",
    "\n",
    "for model_name, (model, _, _) in trained_models.items():\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    results = model.evaluate(val_gen, verbose=0)\n",
    "    results_comparison.append({\n",
    "        'Model': model_name,\n",
    "        'Loss': results[0],\n",
    "        'Accuracy': results[1],\n",
    "        'Top-3 Acc': results[2]\n",
    "    })\n",
    "    print(f\"  Loss: {results[0]:.4f}\")\n",
    "    print(f\"  Accuracy: {results[1]:.4f}\")\n",
    "    print(f\"  Top-3 Accuracy: {results[2]:.4f}\")\n",
    "\n",
    "# Display comparison table\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results_comparison)\n",
    "print(\"\\nComparison Table:\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Save results to CSV\n",
    "df.to_csv(os.path.join(OUTPUT_DIR, 'model_comparison.csv'), index=False)\n",
    "print(f\"\\n✓ Results saved to {os.path.join(OUTPUT_DIR, 'model_comparison.csv')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"Trained models are ready for GradCAM analysis!\")\n",
    "print(f\"Models saved in: {OUTPUT_DIR}\")\n",
    "print(f\"Logs saved in: {LOGS_DIR}\")\n",
    "\n",
    "# Optional: Generate classification reports and confusion matrices\n",
    "def generate_reports(model, model_name, val_gen):\n",
    "    \"\"\"\n",
    "    Generate detailed classification report and confusion matrix\n",
    "    \"\"\"\n",
    "    # Get predictions\n",
    "    val_gen.reset()\n",
    "    predictions = model.predict(val_gen, verbose=0)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "    y_true = val_gen.classes\n",
    "    class_names = list(val_gen.class_indices.keys())\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "    print(f\"\\nClassification Report for {model_name}:\")\n",
    "    print(report)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, model_name, f'{model_name}_confusion_matrix.png'), dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "# Generate reports for all models (optional - uncomment if needed)\n",
    "# for model_name, (model, _, _) in trained_models.items():\n",
    "#     generate_reports(model, model_name, val_gen)\n",
    "\n",
    "print(\"\\nNotebook execution completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
