{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2de28af",
   "metadata": {},
   "source": [
    "# Explain-CNN-With-GANS: Data Preparation Workflow\n",
    "This notebook covers the full data preparation pipeline: dataset download, classifier training, GradCAM/CGMA generation, and .npy creation for GAN training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e93367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install kagglehub tensorflow opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ec5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras import applications as ap\n",
    "import kagglehub\n",
    "import shutil\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc3d4ff",
   "metadata": {},
   "source": [
    "## 1. Download Food-11 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4b70aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = kagglehub.dataset_download(\"trolukovich/food11-image-dataset\")\n",
    "print(\"Path to dataset files:\", dataset_path)\n",
    "target_path = \"Datasets/Food\"\n",
    "try:\n",
    "    shutil.move(dataset_path, target_path)\n",
    "    print(f\"Dataset moved to {target_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not move dataset: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc11e27",
   "metadata": {},
   "source": [
    "## 2. Train Classifiers (InceptionV3, ResNet50, VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64810a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models =[ap.InceptionV3, ap.ResNet50, ap.VGG16]\n",
    "data_paths =['Datasets/Food']\n",
    "model_paths= ['models/Food']\n",
    "backbone_names =['InceptionV3', 'ResNet', 'VGG16']\n",
    "for j, path in enumerate(data_paths):\n",
    "    for i, backbone_model in enumerate(models):\n",
    "        gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255., validation_split=0.1)\n",
    "        train = gen.flow_from_directory(path, target_size=(256,256), batch_size=64, subset='training')\n",
    "        val = gen.flow_from_directory(path, target_size=(256,256), batch_size=64, subset='validation')\n",
    "        m = backbone_model(input_shape=(256,256,3), include_top=False)\n",
    "        m_out = m.output\n",
    "        glob = tf.keras.layers.GlobalMaxPooling2D()(m_out)\n",
    "        d1 = tf.keras.layers.Dense(256, activation='relu', kernel_initializer='he_normal')(glob)\n",
    "        drop = tf.keras.layers.Dropout(0.1)(d1)\n",
    "        d2 = tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal')(d1)\n",
    "        out = tf.keras.layers.Dense(len(np.unique(train.classes)), activation='softmax', kernel_initializer='he_normal')(d2)\n",
    "        model = tf.keras.models.Model(inputs=m.input, outputs=out)\n",
    "        opt = 'adam' if backbone_names[i]=='mobilenet' else 'sgd'\n",
    "        print(f'Model = {backbone_names[i]}')\n",
    "        print(f\"Optimizer = {opt}\")\n",
    "        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        try:\n",
    "            os.makedirs(os.path.join(model_paths[j], backbone_names[i]), exist_ok=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not create model directory: {e}\")\n",
    "        callbacks = [tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', filepath=os.path.join(model_paths[j], backbone_names[i], 'Epoch={epoch:02d}- Loss={val_loss:.2f} - val_acc = {val_accuracy:.2f}.h5'))]\n",
    "        history = model.fit(train, epochs=20, validation_data=val, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d294f101",
   "metadata": {},
   "source": [
    "## 3. Generate GradCAM and CGMA Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb53d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example GradCAM function (simplified)\n",
    "def GradCam(model, img_array, layer_name):\n",
    "    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(layer_name).output, model.output])\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, tf.argmax(predictions[0])]\n",
    "    grads = tape.gradient(loss, conv_outputs)[0]\n",
    "    weights = tf.reduce_mean(grads, axis=(0, 1))\n",
    "    cam = tf.reduce_sum(tf.multiply(weights, conv_outputs[0]), axis=-1)\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / np.max(cam)\n",
    "    cam = cv2.resize(cam.numpy(), (img_array.shape[2], img_array.shape[1]))\n",
    "    return cam\n",
    "# You can loop over images and layers to generate and save GradCAM/CGMA maps as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690badad",
   "metadata": {},
   "source": [
    "## 4. Create .npy File for GAN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146e490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Combine images, GradCAMs, CGMAs, and labels into a single .npy file\n",
    "def create_gan_training_npy(image_folder, gradcam_folder, cgma_folder, labels_file, output_npy):\n",
    "    images = []\n",
    "    gradcams = []\n",
    "    cgmas = []\n",
    "    labels = np.load(labels_file)\n",
    "    for img_name in os.listdir(image_folder):\n",
    "        img = cv2.imread(os.path.join(image_folder, img_name))\n",
    "        images.append(img)\n",
    "        gradcam = np.load(os.path.join(gradcam_folder, img_name.replace('.jpg', '.npy')))\n",
    "        gradcams.append(gradcam)\n",
    "        cgma = np.load(os.path.join(cgma_folder, img_name.replace('.jpg', '.npy')))\n",
    "        cgmas.append(cgma)\n",
    "    np.save(output_npy, {'images': images, 'gradcams': gradcams, 'cgmas': cgmas, 'labels': labels})\n",
    "    print(f'GAN training data saved to {output_npy}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
